# Copyright 2023 KubeAGI.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


import logging
import re
import traceback

import ftfy
import opencc
from selectolax.parser import HTMLParser

from common import log_tag_const, special_characters

logger = logging.getLogger(__name__)


def remove_invisible_characters(text):
    """remove invisible characters.

    text: text;

    usage
    input:
    â€œä¸€æˆ·ä¸€è¡¨ã€æ°´è¡¨å‡ºæˆ·ã€æŠ„è¡¨åˆ°æˆ·â€æ˜¯æŒ‡ä¸€ä¸ªå®¶åº­ç”¨æˆ·å®‰è£…ä¸€ä¸ªè®¡é‡æ°´è¡¨ï¼Œè®¡é‡æ°´è¡¨å®‰è£…åœ¨ä½å®…çš„å…¬å…±éƒ¨ä½ï¼Œä¾›æ°´ä¼ä¸šæŠ„è¡¨åˆ°æˆ·ï¼ŒæŒ‰æˆ·è®¡é‡æ”¶è´¹ã€‚
    output:
    â€œä¸€æˆ·ä¸€è¡¨ã€æ°´è¡¨å‡ºæˆ·ã€æŠ„è¡¨åˆ°æˆ·â€æ˜¯æŒ‡ä¸€ä¸ªå®¶åº­ç”¨æˆ·å®‰è£…ä¸€ä¸ªè®¡é‡æ°´è¡¨ï¼Œè®¡é‡æ°´è¡¨å®‰è£…åœ¨ä½å®…çš„å…¬å…±éƒ¨ä½ï¼Œä¾›æ°´ä¼ä¸šæŠ„è¡¨åˆ°æˆ·ï¼ŒæŒ‰æˆ·è®¡é‡æ”¶è´¹ã€‚
    """
    try:
        pattern = r"[\x00-\x1F\x7F-\x9F\xAD\r\t\b\x0B\x1C\x1D\x1E]"
        find_pattern = (
            r"[^ï¼Œã€‚ï¼ï¼Ÿ,.!?]*[\x00-\x1F\x7F-\x9F\xAD\r\t\b\x0B\x1C\x1D\x1E][^ï¼Œã€‚ï¼ï¼Ÿ,.!?]*"
        )
        replace_text = ""

        clean_text = re.sub(pattern, replace_text, text)

        clean_data = _find_clean_data(
            text=text,
            pattern=pattern,
            find_pattern=find_pattern,
            replace_text=replace_text,
        )
        return {
            "status": 200,
            "message": "",
            "data": {"clean_data": clean_data, "text": clean_text},
        }
    except Exception as ex:
        logger.error(
            "".join(
                [
                    f"{log_tag_const.CLEAN_TRANSFORM} Execute removing invisible characters failed\n",
                    f"The tracing error is: \n{traceback.format_exc()}\n",
                ]
            )
        )
        return {"status": 400, "message": str(ex), "data": traceback.format_exc()}


def space_standardization(text):
    """space standardization.

    text: text;

    usage:
    input:
    ç¬¬ä¸€æ¡ã€€ç­ç«æ˜¯æŒ‡å›½å®¶ç»¼åˆæ€§æ¶ˆé˜²æ•‘æ´é˜Ÿã€ä¸“èŒæ¶ˆé˜²é˜Ÿä¾æ³•æ‰¿æ‹…çš„ç«ç¾æ‰‘æ•‘å·¥ä½œã€‚

    output:
    ç¬¬ä¸€æ¡ ç­ç«æ˜¯æŒ‡å›½å®¶ç»¼åˆæ€§æ¶ˆé˜²æ•‘æ´é˜Ÿã€ä¸“èŒæ¶ˆé˜²é˜Ÿä¾æ³•æ‰¿æ‹…çš„ç«ç¾æ‰‘æ•‘å·¥ä½œã€‚
    """
    try:
        various_whitespaces = special_characters.VARIOUS_WHITESPACES
        pattern = "|".join(re.escape(value) for value in various_whitespaces)
        find_pattern = "|".join(
            f"[^ï¼Œã€‚ï¼ï¼Ÿ,.!?]*{re.escape(value)}[^ï¼Œã€‚ï¼ï¼Ÿ,.!?]*"
            for value in various_whitespaces
        )
        replace_text = " "

        clean_text = re.sub(pattern, replace_text, text)

        clean_data = _find_clean_data(
            text=text,
            pattern=pattern,
            find_pattern=find_pattern,
            replace_text=replace_text,
        )

        return {
            "status": 200,
            "message": "",
            "data": {"clean_data": clean_data, "text": clean_text},
        }
    except Exception as ex:
        logger.error(
            "".join(
                [
                    f"{log_tag_const.CLEAN_TRANSFORM} Executing space standardization failed.\n",
                    f"The tracing error is: \n{traceback.format_exc()}\n",
                ]
            )
        )
        return {"status": 400, "message": str(ex), "data": traceback.format_exc()}


def remove_garbled_text(text):
    """remove garbled text.
    text: text;

    usage:
    input:
    æ±Ÿè‹çœæ»¨æµ·å¿äººæ°‘æ³•é™¢æ°‘äº‹åˆ¤å†³ä¹¦(2015)æ»¨æ»©å•†åˆå­—ç¬¬0014å·åŸå‘Šå­Ÿåº†è¿,ç”·,49å²,å±…æ°‘ã€‚å§”æ‰˜ä»£ç†äººç‹æˆåº­,æ»¨æµ·å¿æ»¨æ·®æ³•å¾‹æœåŠ¡æ‰€æ³•å¾‹å·¥ä½œè€…ã€‚ Ã¢â‚¬â€ like this one.

    output:
    æ±Ÿè‹çœæ»¨æµ·å¿äººæ°‘æ³•é™¢æ°‘äº‹åˆ¤å†³ä¹¦(2015)æ»¨æ»©å•†åˆå­—ç¬¬0014å·åŸå‘Šå­Ÿåº†è¿,ç”·,49å²,å±…æ°‘ã€‚å§”æ‰˜ä»£ç†äººç‹æˆåº­,æ»¨æµ·å¿æ»¨æ·®æ³•å¾‹æœåŠ¡æ‰€æ³•å¾‹å·¥ä½œè€…ã€‚ â€” like this one.

    """
    try:
        clean_text = ftfy.fix_text(text)
        return {"status": 200, "message": "", "data": {"found": 0, "text": clean_text}}

    except Exception as ex:
        error = str(ex)
        logger.error(
            "".join(
                [
                    f"{log_tag_const.CLEAN_TRANSFORM} Executing space standardization failed\n",
                    f"The tracing error is: \n{traceback.format_exc()}\n",
                ]
            )
        )

        return {"status": 400, "message": error, "data": traceback.format_exc()}


def traditional_to_simplified(text):
    """Traditional Chinese to Simplified Chinese.

    text: text;

    usage:
    input:
    é¢¨æš´å¸¶ä¾†çš„æš«åœä½¿æ¶ˆé˜²å“¡å’Œå…¶ä»–ç·Šæ€¥åæ‡‰äººå“¡å¾—ä»¥é€²å…¥ç¦å€é€²è¡Œçµæ§‹ç ´å£è©•ä¼°ã€‚

    output:
    é£æš´å¸¦æ¥çš„æš‚åœä½¿æ¶ˆé˜²å‘˜å’Œå…¶ä»–ç´§æ€¥ååº”äººå‘˜å¾—ä»¥è¿›å…¥ç¦åŒºè¿›è¡Œç»“æ„ç ´åè¯„ä¼°ã€‚
    """
    try:
        clean_text = opencc.OpenCC("t2s").convert(text)

        return {"status": 200, "message": "", "data": {"found": 0, "text": clean_text}}
    except Exception as ex:
        error = str(ex)
        logger.error(
            "".join(
                [
                    f"{log_tag_const.CLEAN_TRANSFORM} Executing Traditional Chinese to Simplified Chinese failed\n",
                    f"The tracing error is: \n{traceback.format_exc()}\n",
                ]
            )
        )

        return {"status": 400, "message": error, "data": traceback.format_exc()}


def remove_html_tag(text):
    """clean html code in text samples.

    text: text;

    usage:
    input:
    <div class='center'><span class='bolded'>æœ—æ’­ SAT å­¦å‘˜æˆç»©å•åˆ†ææŠ¥å‘Š

    output:
    æœ—æ’­ SAT å­¦å‘˜æˆç»©å•åˆ†ææŠ¥å‘Š
    """
    try:
        text = text.replace("<li>", "\n*")
        text = text.replace("</li>", "")
        text = text.replace("<ol>", "\n*")
        text = text.replace("</ol>", "")
        parser = HTMLParser(text)

        clean_text = parser.text()

        return {"status": 200, "message": "", "data": {"found": 0, "text": clean_text}}
    except Exception as ex:
        error = str(ex)
        logger.error(
            "".join(
                [
                    f"{log_tag_const.CLEAN_TRANSFORM} Executing clean html code in text samples failed\n",
                    f"The tracing error is: \n{traceback.format_exc()}\n",
                ]
            )
        )

        return {"status": 400, "message": error, "data": traceback.format_exc()}


def remove_emojis(text):
    """remove emojis.

    text: text;

    usage:
    input:
    è¿™æ˜¯ä¸€æ®µå¸¦æœ‰è¡¨æƒ…ç¬¦å·ğŸ˜Šçš„æ–‡æœ¬ã€‚

    output:
    è¿™æ˜¯ä¸€æ®µå¸¦æœ‰è¡¨æƒ…ç¬¦å·çš„æ–‡æœ¬ã€‚
    """
    try:
        emojis = special_characters.EMOJI
        pattern = "|".join(re.escape(value) for value in emojis)
        find_pattern = "|".join(
            f"[^ï¼Œã€‚ï¼ï¼Ÿ,.!?]*{re.escape(value)}[^ï¼Œã€‚ï¼ï¼Ÿ,.!?]*" for value in emojis
        )
        replace_text = ""

        clean_text = re.sub(pattern, replace_text, text)

        clean_data = _find_clean_data(
            text=text,
            pattern=pattern,
            find_pattern=find_pattern,
            replace_text=replace_text,
        )

        return {
            "status": 200,
            "message": "",
            "data": {"clean_data": clean_data, "text": clean_text},
        }

    except Exception as ex:
        error = str(ex)
        logger.error(
            "".join(
                [
                    f"{log_tag_const.CLEAN_TRANSFORM} Executing remove emojis failed\n",
                    f"The tracing error is: \n{traceback.format_exc()}\n",
                ]
            )
        )

        return {"status": 400, "message": error, "data": traceback.format_exc()}


def _find_clean_data(text, pattern, find_pattern, replace_text):
    """find clean data for pre_content and post_content.

    text: text;
    pattern: ;
    find_pattern: ;

    """
    clean_data = []

    sentences = re.findall(find_pattern, text)
    for sentence in sentences:
        post_content = re.sub(pattern, replace_text, sentence)
        clean_data.append({"pre_content": sentence, "post_content": post_content})

    return clean_data
