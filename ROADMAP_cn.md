## Roadmap of KubeAGI

### v0.1.0 - 2023 Q4, 即将发布

* 数据集管理 - 对数据进行管理，包括本地上传、对接对象存储、数据编辑、版本控制、下载等
* 数据处理 - 数据清洗、文本拆分（文本分段、QA拆分）、文件标签
* 知识库 - 对处理后的数据进行向量化处理
* 模型管理 - 对模型进行生命周期管理
* 模型服务
  - 支持 CPU & GPU Model Serving
  - 支持 remote/local 两类模型推理服务，并关联知识库
  - 支持本地 Embedding 服务（bge，m3e）
  - 支持使用 vLLM 推理引擎
* 模型应用 - Prompt Engineering，初步实现 LLM 应用的编排能力，支持 Prompt、LLM/Retriever Chain节点的管理及编排，提供相关示例应用（基于 streamlit）
* 引导、示例场景 - 通过向导方式引导用户平台使用流程；内置 chat 示例应用

### v0.2.0 - 2024 Feb.
* 支持 Prompt 在不同 LLM 下的评估，生成测试报告
* RAG 评估、RAG Question Generation
  - 优化问题自动生成，分析问题质量，过滤掉相似度不高的问题
  - 评估指标：检索评估 - Hit Rate、MRR，回答评估 - 公正性、相关性、一致性等
  -  其他评估能力

* 数据血缘，掌握数据的来龙去脉，比如：支持回答与原始文档关系映射
* 对大模型生成的 QA 对进行相似度分析，允许用户手动处理（删除、合并等）

* 数据集、知识库、模型服务等基于 streamlit 的 playground
* 模型应用支持 Get/Post API Chain，支持典型 LLM 应用开发（非工作流模式）
* 基于 streamlit，支持各类数据的可视化

### v0.3.0 - 2024 Mar.
* 数据处理 - 引入文本标注（自动 + 人工），提高数据质量（辅助微调）
* 数据安全 - 支持数据脱敏（身份证、电话、银行卡号等）
* 数据源增加更多数据集成能力（数据库、API等），同时支持数据的同步策略（自动同步）

* 支持人工评测，把控 dev 到 prod 之前的质量；同时，将人工反馈加入到监控系统
* 支持线上用户对问答的反馈，从而促进 LLM 应用的优化（数据处理、Prompt 等方面）

* 集成容器 GPU 管理、调度及资源监控能力
* 集成 API 网关，支持模型服务 API 的治理（监控、分析、安全等）

### v0.5.0 - 2024 Apr.
* 支持低资源大模型微调，包括RLHF、SFT（Adapter、P-tuning、LoRA），提高模型质量，降低对模型服务性能要求（降低推理成本、延迟（Prompt 较长、推理较慢等情况）
* 模型压缩
* 对模型服务、Embedding 进行测试并评估（QA评估、指标采集）

* Scale to zero(对接 arbiter)，cold start，让模型、应用向 Serverless 演进

* 支持 Agent、Cache 等更多节点类型的编排
* 引入更多提示词工程最佳实践
  - few shots
  - Chain-of-Thought（CoT）
  - 思维树

### v1.0 - 2024 Jun.
* 根据数据标注，自动构建 Prompt 模版
* 增强 LLMOps 的监控能力，数据集 + 特征数据-> 模型 -> 推理的监控，调用链路跟踪（基于 langchain-go）
* 实现从数据源->数据集->数据处理->数据版本->知识库->模型服务的流水线
* 强化 python SDK 来操作数据集、数据处理、向量化等基础能力，可以在 notebook 中完成相关操作：
* Databricks 参考，提高开发者体验
* 基于网关，实现 LLM 应用的灰度发布，支持对应用版本的小范围测试
