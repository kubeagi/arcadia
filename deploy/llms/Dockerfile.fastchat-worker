FROM nvidia/cuda:12.2.0-devel-ubuntu20.04


# Define a build argument with a default value
ARG PACKAGE_REGISTRY="mirrors.tuna.tsinghua.edu.cn"

# Update the package registry based on the build argument
RUN sed -i "s/archive.ubuntu.com/$PACKAGE_REGISTRY/g" /etc/apt/sources.list \
    && sed -i "s/security.ubuntu.com/$PACKAGE_REGISTRY/g" /etc/apt/sources.list

# Configure the default Timezone
ENV TZ=Asia/Shanghai
RUN export DEBIAN_FRONTEND=noninteractive \
    && apt-get update \
    && apt-get install -y tzdata git \
    && ln -fs /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \
    && dpkg-reconfigure --frontend noninteractive tzdata

# Official: https://pypi.org/simple
ARG PYTHON_INDEX_URL="https://pypi.mirrors.ustc.edu.cn/simple/"

# Install fastchat along with its dependencies
RUN apt-get install -y python3.9 python3.9-distutils curl python3-pip python3-dev gcc
RUN python3.9 -m pip install tomli setuptools_scm wavedrom transformers==4.37.0 -i ${PYTHON_INDEX_URL}
RUN python3.9 -m pip install --upgrade pip -i ${PYTHON_INDEX_URL}
RUN git clone https://github.com/lm-sys/FastChat.git \
    && cd FastChat \
    && python3.9 -m pip install -e ".[model_worker]"  -i ${PYTHON_INDEX_URL} \
    && git rev-parse HEAD > $HOME/.fastchat \
    && cd ..

# Configure the following environment variables to allow fastchat to pull model files from modelscope
# export VLLM_USE_MODELSCOPE=True ,export FASTCHAT_USE_MODELSCOPE=True
RUN python3.9 -m pip install modelscope pydantic==1.10.14 -i ${PYTHON_INDEX_URL}

# Install requirements for QWen(https://huggingface.co/Qwen/Qwen-72B-Chat)
RUN python3.9 -m pip install einops scipy transformers_stream_generator==0.0.4 deepspeed -i ${PYTHON_INDEX_URL}

# Install requirements for Qutantization with auto-gptq
RUN python3.9 -m pip install auto-gptq optimum -i ${PYTHON_INDEX_URL}

# Install requirements for BGEReranking(https://stackoverflow.com/questions/65431837/transformers-v4-x-convert-slow-tokenizer-to-fast-tokenizer0)
RUN python3.9 -m pip install sentencepiece -i ${PYTHON_INDEX_URL}

COPY deploy/llms/start-worker.sh /
ENTRYPOINT ["/start-worker.sh"]
