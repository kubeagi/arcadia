apiVersion: arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: Application
metadata:
  name: base-chat-with-bot-bing
  namespace: arcadia
spec:
  displayName: "å¯¹è¯æœºå™¨äºº"
  description: "å’ŒAIå¯¹è¯ï¼Œå“èµ›åšäººç”Ÿ"
  prologue: "Hello, I am KubeAGI BotğŸ¤–, Tell me something?"
  nodes:
    - name: Input
      displayName: "ç”¨æˆ·è¾“å…¥"
      description: "ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹ï¼Œå¿…é¡»"
      ref:
        kind: Input
        name: Input
      nextNodeName: ["prompt-node"]
    - name: prompt-node
      displayName: "prompt"
      description: "è®¾å®špromptï¼Œtemplateä¸­å¯ä»¥ä½¿ç”¨{{xx}}æ¥æ›¿æ¢å˜é‡"
      ref:
        apiGroup: prompt.arcadia.kubeagi.k8s.com.cn
        kind: Prompt
        name: base-chat-with-bot-bing
      nextNodeName: ["chain-node"]
    - name: llm-node
      displayName: "zhipuå¤§æ¨¡å‹æœåŠ¡"
      description: "è®¾å®šå¤§æ¨¡å‹çš„è®¿é—®ä¿¡æ¯"
      ref:
        apiGroup: arcadia.kubeagi.k8s.com.cn
        kind: LLM
        name: app-shared-llm-service
      nextNodeName: ["chain-node"]
    - name: chain-node
      displayName: "llm chain"
      description: "chainæ˜¯langchainçš„æ ¸å¿ƒæ¦‚å¿µï¼ŒllmChainç”¨äºè¿æ¥promptå’Œllm"
      ref:
        apiGroup: chain.arcadia.kubeagi.k8s.com.cn
        kind: LLMChain
        name: base-chat-with-bot-bing
      nextNodeName: ["Output"]
    - name: Output
      displayName: "æœ€ç»ˆè¾“å‡º"
      description: "æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹ï¼Œå¿…é¡»"
      ref:
        kind: Output
        name: Output
---
apiVersion: prompt.arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: Prompt
metadata:
  name: base-chat-with-bot-bing
  namespace: arcadia
  annotations:
    arcadia.kubeagi.k8s.com.cn/input-rules: '[{"kind":"Input","length":1}]'
    arcadia.kubeagi.k8s.com.cn/output-rules: '[{"length":1}]'
spec:
  displayName: "è®¾å®šå¯¹è¯çš„prompt"
  description: "è®¾å®šå¯¹è¯çš„prompt"
  userMessage: |
    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    Current Context: 
    {{.context}}
    
    Current conversation:
    {{.history}}
    
    Human: {{.question}}
    AI:
---
apiVersion: chain.arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: LLMChain
metadata:
  name: base-chat-with-bot-bing
  namespace: arcadia
  annotations:
    arcadia.kubeagi.k8s.com.cn/input-rules: '[{"kind":"LLM","group":"arcadia.kubeagi.k8s.com.cn","length":1},{"kind":"prompt","group":"prompt.arcadia.kubeagi.k8s.com.cn","length":1}]'
    arcadia.kubeagi.k8s.com.cn/output-rules: '[{"kind":"Output","length":1}]'
spec:
  displayName: "llm chain"
  description: "llm chain"
  memory:
    conversionWindowSize: 2
  model: chatglm_turbo # notice: default model chatglm_lite gets poor results in most cases, openai's gpt-3.5-turbo is also good enough
  tools:
    - name: bing
