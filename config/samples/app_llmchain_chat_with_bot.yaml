apiVersion: arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: Application
metadata:
  name: base-chat-with-bot
  namespace: arcadia
spec:
  displayName: "å¯¹è¯æœºå™¨äºº"
  description: "å’ŒAIå¯¹è¯ï¼Œå“èµ›åšäººç”Ÿ"
  prologue: "Hello, I am KubeAGI BotğŸ¤–, Tell me something?"
  nodes:
    - name: Input
      displayName: "ç”¨æˆ·è¾“å…¥"
      description: "ç”¨æˆ·è¾“å…¥èŠ‚ç‚¹ï¼Œå¿…é¡»"
      ref:
        kind: Input
        name: Input
      nextNodeName: ["prompt-node"]
    - name: prompt-node
      displayName: "prompt"
      description: "è®¾å®špromptï¼Œtemplateä¸­å¯ä»¥ä½¿ç”¨{{xx}}æ¥æ›¿æ¢å˜é‡"
      ref:
        apiGroup: prompt.arcadia.kubeagi.k8s.com.cn
        kind: Prompt
        name: base-chat-with-bot
      nextNodeName: ["chain-node"]
    - name: llm-node
      displayName: "zhipuå¤§æ¨¡å‹æœåŠ¡"
      description: "è®¾å®šè´¨è°±å¤§æ¨¡å‹çš„è®¿é—®ä¿¡æ¯"
      ref:
        apiGroup: arcadia.kubeagi.k8s.com.cn
        kind: LLM
        name: base-chat-with-bot
      nextNodeName: ["chain-node"]
    - name: chain-node
      displayName: "llm chain"
      description: "chainæ˜¯langchainçš„æ ¸å¿ƒæ¦‚å¿µï¼ŒllmChainç”¨äºè¿æ¥promptå’Œllm"
      ref:
        apiGroup: chain.arcadia.kubeagi.k8s.com.cn
        kind: LLMChain
        name: base-chat-with-bot
      nextNodeName: ["Output"]
    - name: Output
      displayName: "æœ€ç»ˆè¾“å‡º"
      description: "æœ€ç»ˆè¾“å‡ºèŠ‚ç‚¹ï¼Œå¿…é¡»"
      ref:
        kind: Output
        name: Output
---
apiVersion: prompt.arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: Prompt
metadata:
  name: base-chat-with-bot
  namespace: arcadia
spec:
  displayName: "è®¾å®šå¯¹è¯çš„prompt"
  description: "è®¾å®šå¯¹è¯çš„prompt"
  userMessage: |
    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.

    Current conversation:
    {{.history}}
    Human: {{.question}}
    AI:
  input:
    kind: "Input"
    name: "Input"
  output:
    apiGroup: chain.arcadia.kubeagi.k8s.com.cn
    kind: LLMChain
    name: base-chat-with-bot
---
apiVersion: chain.arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: LLMChain
metadata:
  name: base-chat-with-bot
  namespace: arcadia
spec:
  displayName: "llm chain"
  description: "llm chain"
  memory:
    conversionWindowSize: 2
  model: chatglm_turbo # notice: default model chatglm_lite gets poor results in most cases, openai's gpt-3.5-turbo is also good enough
  input:
    llm:
      apiGroup: arcadia.kubeagi.k8s.com.cn
      kind: LLM
      name: base-chat-with-bot
    prompt:
      apiGroup: prompt.arcadia.kubeagi.k8s.com.cn
      kind: Prompt
      name: base-chat-with-bot
  output:
    apiGroup: "arcadia.kubeagi.k8s.com.cn"
    kind: "Output"
    name: "output-node"
---
apiVersion: v1
kind: Secret
metadata:
  name: base-chat-with-bot
  namespace: arcadia
type: Opaque
data:
  apiKey: "MTZlZDcxYzcwMDE0NGFiMjIyMmI5YmEwZDFhMTBhZTUuUTljWVZtWWxmdjlnZGtDeQ==" # replace this with your API key
---
apiVersion: arcadia.kubeagi.k8s.com.cn/v1alpha1
kind: LLM
metadata:
  name: base-chat-with-bot
  namespace: arcadia
spec:
  type: "zhipuai"
  provider:
    endpoint:
      url: "https://open.bigmodel.cn/api/paas/v3/model-api" # replace this with your LLM URL(Zhipuai use predefined url https://open.bigmodel.cn/api/paas/v3/model-api)
      authSecret:
        kind: secret
        name: base-chat-with-bot
